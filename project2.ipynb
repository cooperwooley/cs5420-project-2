{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5caeed4",
   "metadata": {},
   "source": [
    "# Project 2: NB Classifier\n",
    "\n",
    "### Course: CS 5420\n",
    "\n",
    "### Author: Cooper Wooley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "504e5dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import atexit\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d514dee6",
   "metadata": {},
   "source": [
    "### Helper Functions for Managing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "299de0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataset(zip_path):\n",
    "    # Create a temporary directory to extract into\n",
    "    temp_dir = tempfile.mkdtemp(prefix=\"dataset_\")\n",
    "\n",
    "    # Extract contents\n",
    "    with tarfile.open(zip_path, 'r:gz') as tar_ref:\n",
    "        tar_ref.extractall(temp_dir)\n",
    "\n",
    "    # Register cleanup handler so even if program crashes, data is removed\n",
    "    atexit.register(lambda: cleanup_dataset(temp_dir))\n",
    "\n",
    "    # Find the first subdirectory inside extracted directory\n",
    "    contents = [os.path.join(temp_dir, d) for d in os.listdir(temp_dir)]\n",
    "    subdirs = [d for d in contents if os.path.isdir(d)]\n",
    "\n",
    "    if len(subdirs) == 1:\n",
    "        data_root = subdirs[0]\n",
    "    else:\n",
    "        data_root = temp_dir # fallback if already data root\n",
    "\n",
    "    return data_root\n",
    "\n",
    "def cleanup_dataset(directory):\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "        print(f\"Cleaned up dataset directory: {directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b58d72",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6771b539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2003v\\AppData\\Local\\Temp\\ipykernel_18880\\4247884268.py:7: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar_ref.extractall(temp_dir)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset extracted to : C:\\Users\\2003v\\AppData\\Local\\Temp\\dataset_qc_wwiax\\20_newsgroups\n"
     ]
    }
   ],
   "source": [
    "tar_path = \"20_newsgroups.tar.gz\"\n",
    "extracted_path = extract_dataset(tar_path)\n",
    "print(f\"Dataset extracted to : {extracted_path}\")\n",
    "\n",
    "def split_dataset(base_dir, train_ratio=0.5, seed=42):\n",
    "    random.seed(seed)\n",
    "\n",
    "    train_files = []\n",
    "    test_files = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "\n",
    "    for d in os.listdir(base_dir):\n",
    "        d_path = os.path.join(base_dir, d)\n",
    "        if not os.path.isdir(d_path):\n",
    "            continue\n",
    "\n",
    "        files = [\n",
    "            os.path.join(d_path, f)\n",
    "            for f in os.listdir(d_path)\n",
    "            if os.path.isfile(os.path.join(d_path, f))\n",
    "        ]\n",
    "\n",
    "        random.shuffle(files)\n",
    "        split_index = int(len(files) * train_ratio)\n",
    "\n",
    "        train_files.extend(files[:split_index])\n",
    "        test_files.extend(files[split_index:])\n",
    "        train_labels.extend([d] * split_index)\n",
    "        test_labels.extend([d] * (len(files) - split_index))\n",
    "\n",
    "    return train_files, test_files, train_labels, test_labels # train_X, test_Y, train_Y, test_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8c15d2-fdbd-4011-9087-9bc538f697b6",
   "metadata": {},
   "source": [
    "## NB Classifier\n",
    "\n",
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6187e5ac-34a9-4c3c-8da3-f5dcae7fd234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(train_files, train_labels, laplace_smooth=False):\n",
    "    vocab = set()\n",
    "    word_counts = defaultdict(Counter) # class: {word: count}\n",
    "    classes = set(train_labels)\n",
    "    total_docs = len(train_labels)\n",
    "\n",
    "    for path, label in zip(train_files, train_labels):\n",
    "        with open(path, 'r', errors='ignore') as f:\n",
    "            # Tokenize\n",
    "            words = re.findall(r'\\b\\w+\\b', f.read().lower())\n",
    "            vocab.update(w for w in words)\n",
    "            word_counts[label].update(words)\n",
    "\n",
    "    # Compute P(Y)\n",
    "    priors = {}\n",
    "    classes = set(train_labels)\n",
    "    for cls in classes:\n",
    "        priors[cls] = train_labels.count(cls) / total_docs\n",
    "\n",
    "    # Compute P(X|Y)\n",
    "    likelihoods = {}\n",
    "\n",
    "    for cls, words in word_counts.items():\n",
    "        total_words = sum(words.values())\n",
    "        class_likelihoods = {}\n",
    "        for word, count in words.items():\n",
    "            class_likelihoods[word] = (count + int(laplace_smooth)) / (total_words + (int(laplace_smooth) * len(vocab)))\n",
    "        likelihoods[cls] = class_likelihoods\n",
    "        \n",
    "    return priors, likelihoods, len(vocab), laplace_smooth, {cls: sum(words.values()) for cls, words in word_counts.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04259254-7aa0-4d62-932f-8a783fce5324",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94254dc1-37e2-48af-9b7c-65909ebce0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, priors, likelihoods, log_prob=False, vocab_size=None, laplace_smooth=False, word_counts=None):\n",
    "    with open(text, 'r', errors='ignore') as f:\n",
    "        words = re.findall(r'\\b\\w+\\b', f.read().lower())\n",
    "\n",
    "    score = {}\n",
    "    for cls, _ in priors.items():\n",
    "        score[cls] = math.log(priors[cls]) if log_prob else priors[cls]\n",
    "\n",
    "        for word in words:\n",
    "            if word in likelihoods[cls]:\n",
    "                if log_prob:\n",
    "                    score[cls] += math.log(likelihoods[cls][word])\n",
    "                else:\n",
    "                    score[cls] *= likelihoods[cls][word]\n",
    "            else:\n",
    "                # Handle unseen words with laplace smoothing\n",
    "                if laplace_smooth:\n",
    "                    if log_prob:\n",
    "                        score[cls] += math.log(1 / (word_counts[cls] + vocab_size))\n",
    "                    else:\n",
    "                        score[cls] *= 1 / (word_counts[cls] + vocab_size)\n",
    "\n",
    "    return max(score, key=score.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cdb5a3-8704-43d4-b748-f1db7f993839",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b19d370e-6b97-40bc-a9f9-2772eabe865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_files, test_labels, priors, likelihoods, log_prob=False, vocab_size=None, laplace_smooth=False, word_counts=None):\n",
    "    correct = 0\n",
    "    for file, y in zip(test_files, test_labels):\n",
    "        y_hat = predict(file, priors, likelihoods, log_prob, vocab_size, laplace_smooth, word_counts)\n",
    "        if y_hat == y:\n",
    "            correct += 1\n",
    "    return correct / len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee0c5cd3-7493-422f-904a-eccc19ab319f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0446\n"
     ]
    }
   ],
   "source": [
    "train_files, test_files, train_labels, test_labels = split_dataset(extracted_path)\n",
    "\n",
    "priors, likelihoods, _, _, _ = train_naive_bayes(train_files, train_labels)\n",
    "\n",
    "accuracy_base = evaluate(test_files, test_labels, priors, likelihoods)\n",
    "print(f\"Accuracy: {accuracy_base:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5cdf5b",
   "metadata": {},
   "source": [
    "## Expanding NB BoW Classifier\n",
    "\n",
    "Below is the implementation of the NB BoW Classifier utilizing Laplace smoothing when computing likelihoods, using log probability when classifying, and filtering words that are not in the training vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a1b3896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8497\n",
      "\n",
      "Difference of accuracy between classifiers: 0.8051\n"
     ]
    }
   ],
   "source": [
    "priors, likelihoods, vocab_size, laplace_smooth, word_counts = train_naive_bayes(train_files, train_labels, laplace_smooth=True)\n",
    "\n",
    "accuracy_expand = evaluate(test_files, test_labels, priors, likelihoods, log_prob=True, vocab_size=vocab_size, laplace_smooth=laplace_smooth, word_counts=word_counts)\n",
    "print(f\"Accuracy: {accuracy_expand:.4f}\")\n",
    "\n",
    "print(f\"\\nDifference of accuracy between classifiers: {abs(accuracy_expand - accuracy_base):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc46f0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up dataset directory: C:\\Users\\2003v\\AppData\\Local\\Temp\\dataset_qc_wwiax\\20_newsgroups\n"
     ]
    }
   ],
   "source": [
    "cleanup_dataset(extracted_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
