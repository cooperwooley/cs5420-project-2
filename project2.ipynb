{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5caeed4",
   "metadata": {},
   "source": [
    "# Project 2: NB Classifier\n",
    "\n",
    "### Course: CS 5420\n",
    "\n",
    "### Author: Cooper Wooley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e5dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import atexit\n",
    "from collections import defaultdict, Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d514dee6",
   "metadata": {},
   "source": [
    "### Helper Functions for Managing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "299de0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataset(zip_path):\n",
    "    # Create a temporary directory to extract into\n",
    "    temp_dir = tempfile.mkdtemp(prefix=\"dataset_\")\n",
    "\n",
    "    # Extract contents\n",
    "    with tarfile.open(zip_path, 'r:gz') as tar_ref:\n",
    "        tar_ref.extractall(temp_dir)\n",
    "\n",
    "    # Register cleanup handler so even if program crashes, data is removed\n",
    "    atexit.register(lambda: cleanup_dataset(temp_dir))\n",
    "\n",
    "    # Find the first subdirectory inside extracted directory\n",
    "    contents = [os.path.join(temp_dir, d) for d in os.listdir(temp_dir)]\n",
    "    subdirs = [d for d in contents if os.path.isdir(d)]\n",
    "\n",
    "    if len(subdirs) == 1:\n",
    "        data_root = subdirs[0]\n",
    "    else:\n",
    "        data_root = temp_dir # fallback if already data root\n",
    "\n",
    "    return data_root\n",
    "\n",
    "def cleanup_dataset(directory):\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "        print(f\"Cleaned up dataset directory: {directory}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b58d72",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6771b539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coope\\AppData\\Local\\Temp\\ipykernel_21612\\3284039328.py:7: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar_ref.extractall(temp_dir)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset extracted to : C:\\Users\\coope\\AppData\\Local\\Temp\\dataset_24i5zz9m\\20_newsgroups\n"
     ]
    }
   ],
   "source": [
    "tar_path = \"20_newsgroups.tar.gz\"\n",
    "extracted_path = extract_dataset(tar_path)\n",
    "print(f\"Dataset extracted to : {extracted_path}\")\n",
    "\n",
    "def split_dataset(base_dir, train_ratio=0.5, seed=42):\n",
    "    random.seed(seed)\n",
    "\n",
    "    train_files = []\n",
    "    test_files = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "\n",
    "    for d in os.listdir(base_dir):\n",
    "        d_path = os.path.join(base_dir, d)\n",
    "        if not os.path.isdir(d_path):\n",
    "            continue\n",
    "\n",
    "        files = [\n",
    "            os.path.join(d_path, f)\n",
    "            for f in os.listdir(d_path)\n",
    "            if os.path.isfile(os.path.join(d_path, f))\n",
    "        ]\n",
    "\n",
    "        random.shuffle(files)\n",
    "        split_index = int(len(files) * train_ratio)\n",
    "\n",
    "        train_files.extend(files[:split_index])\n",
    "        test_files.extend(files[split_index:])\n",
    "        train_labels.extend([d] * split_index)\n",
    "        test_labels.extend([d] * split_index)\n",
    "\n",
    "    return train_files, test_files, train_labels, test_labels # train_X, test_Y, train_Y, test_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8c15d2-fdbd-4011-9087-9bc538f697b6",
   "metadata": {},
   "source": [
    "## NB Classifier\n",
    "\n",
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6187e5ac-34a9-4c3c-8da3-f5dcae7fd234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(train_files, train_labels):\n",
    "    word_counts = defaultdict(Counter) # class: {word: count}\n",
    "    classes = set(train_labels)\n",
    "    total_docs = len(train_labels)\n",
    "\n",
    "    for path, label in zip(train_files, train_labels):\n",
    "        with open(path, 'r', errors='ignore') as f:\n",
    "            words = f.read().lower().split()\n",
    "            word_counts[label].update(words)\n",
    "\n",
    "    # Compute P(Y)\n",
    "    priors = {}\n",
    "    classes = set(train_labels)\n",
    "    for cls in classes:\n",
    "        priors[cls] = train_labels.count(cls) / total_docs\n",
    "\n",
    "    # Compute P(X|Y)\n",
    "    likelihoods = {}\n",
    "\n",
    "    for cls, words in word_counts.items():\n",
    "        total_words = sum(words.values())\n",
    "        class_likelihoods = {}\n",
    "        for word, count in words.items():\n",
    "            class_likelihoods[word] = count / total_words\n",
    "        likelihoods[cls] = class_likelihoods\n",
    "        \n",
    "    return priors, likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04259254-7aa0-4d62-932f-8a783fce5324",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94254dc1-37e2-48af-9b7c-65909ebce0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, priors, likelihoods):\n",
    "    with open(text, 'r', errors='ignore') as f:\n",
    "        words = f.read().lower().split()\n",
    "\n",
    "    score = {}\n",
    "    for cls, _ in priors.items():\n",
    "        score[cls] = priors[cls]\n",
    "        for word in words:\n",
    "            if word not in likelihoods[cls]:\n",
    "                continue\n",
    "            score[cls] *= likelihoods[cls][word]\n",
    "            \n",
    "    return max(score, key=score.get)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cdb5a3-8704-43d4-b748-f1db7f993839",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b19d370e-6b97-40bc-a9f9-2772eabe865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_files, test_labels, priors, likelihoods):\n",
    "    correct = 0\n",
    "    for file, y in zip(test_files, test_labels):\n",
    "        y_hat = predict(file, priors, likelihoods)\n",
    "        if y_hat == y:\n",
    "            correct += 1\n",
    "    return correct / len(test_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee0c5cd3-7493-422f-904a-eccc19ab319f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.03\n"
     ]
    }
   ],
   "source": [
    "train_files, test_files, train_labels, test_labels = split_dataset(extracted_path)\n",
    "\n",
    "priors, likelihoods = train_naive_bayes(train_files, train_labels)\n",
    "\n",
    "accuracy = evaluate(test_files, test_labels, priors, likelihoods)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e539bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up dataset directory: C:\\Users\\coope\\AppData\\Local\\Temp\\dataset_24i5zz9m\\20_newsgroups\n"
     ]
    }
   ],
   "source": [
    "cleanup_dataset(extracted_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
